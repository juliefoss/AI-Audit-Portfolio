risk-classification_Foss.md
# AI Tool Risk Classification – Module 4 **Your Name: Julie Foss** **Date: 7/15/25** **Institution / Organisation: True Nexus Consulting LLC** **Job Title / Role: Consultant** ---
## 1. Name of AI System Briefly name the AI tool or system (e.g. Chatbot, Proctoring AI, CV Screening Tool, Adaptive Platform). --- LexiTutor is platform used to support reading development in Year 5, multilingual classrooms. 
## 2. What Does It Do? Explain the tool’s function, users, and purpose. Include: - Who uses it (staff, students, admin?) - What decisions it supports or automates - What kind of data it processes --- 1. LexiTutor records voice samples of students reading aloud. Student voices are a special category use of data, 2. LexiTutor provides feedback on pronunciation, pace, and tone and flags students who might need extra support. 3. LexiTutor stores user data to personalize reading materials over time.  
## 3. Risk Classification Choose one: - [ ] Minimal Risk - [ ] Limited (Medium) Risk - [ ] High Risk - [ ] Unacceptable Risk - [ X] It Depends --- 
## 4. Justification Explain why you selected that risk level. Address: - Whether the AI system influences rights, outcomes, or access - If it makes decisions automatically - If sensitive or biometric data is used - Whether a human is still involved - If it could cause harm if used incorrectly If you selected “It Depends,” explain what conditions would increase or lower the risk level. --- The recording of student voices is high risk given that voices are biometric data. However, risk could be reduced if the platform did not store or use the data for training purposes. If teachers were using the data from the platform to make decisions about student supports without any oversight or discernment, this platform could be considered high risk. If they are using the data as a piece of data in addition to what they are noticing in class and looking at it against other student work, that risk could be reduced. The potential for students to have different access to learning experiences if their accents cannot be recognized would make this platfrom high risk. If the vendor regularly tested their platform for algorithmic bias and the school team met regularly to ensure their data was not disproporationaltey mismatched for certain students, that would reduce the risk associated with the tool. 
## 5. Reflection  What are the consequences if this AI tool is misclassified or misused? What safeguards would you recommend to school leadership? --- Our course materials were clear that risk assessment is a judgement call. There has to be some tolerance for learning and mistakes as long as oversight, clear owners, communication and risk response protocols, as well as a well intentioned effort to mitigate risk are in place, otherwise nobody would ever take a risk. Starting with a clear purpose for use of tools, intent to do good, and clear actions to mitigate harm and be accountable to a swift and complete response in the event of misuse is my recommendation. 
